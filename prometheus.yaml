---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: prometheus
---
# The ClusterRole grants the Prometheus Service Account permissions to fetch Kubernetes Node information, 
# as well as information about Services, Endpoints, and Pods in the cluster.
apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRole
metadata:
  name: prometheus
rules:
- apiGroups: [""]
  resources:
  - nodes
  - nodes/metrics
  - services
  - endpoints
  - pods
  verbs: ["get", "list", "watch"]
- apiGroups: [""]
  resources: ["configmaps"]
  verbs: ["get"]
- nonResourceURLs: ["/metrics", "/metrics/cadvisor"]
  verbs: ["get"]
---
apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRoleBinding
metadata:
  name: prometheus
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: prometheus
subjects:
- kind: ServiceAccount
  name: prometheus
  namespace: monitoring
---

# alerts.yaml and rules.yaml generated using kubernetes-mixin (https://github.com/kubernetes-monitoring/kubernetes-mixin)
# 
# prometheus.yaml sourced from https://github.com/GoogleCloudPlatform/click-to-deploy/blob/master/k8s/prometheus/manifest/prometheus-configmap.yaml
# and modified to work with DigitalOcean Kubernetes
apiVersion: v1
kind: ConfigMap
metadata:
  creationTimestamp: null
  name: monitoring-prometheus-config
  labels:
    app.kubernetes.io/name: monitoring
    app.kubernetes.io/component: prometheus
data:
  # If you'd like to add your own alerts or modify existing alerts, you can edit this ConfigMap value.
  alerts.yaml: |-
    groups:
      - name: Website HTTP Status Monitoring
        rules:
          - alert: service_down_for_ooscj.co.in
            expr: probe_http_status_code{instance="https://windvista.co.in",job="blackbox"} != 200
            for: 1m
            labels:
              severity: critical
            annotations: 
              message: "HTTP status code for mkasd.co.in is not 200. The website is down."
          - alert: service_down_for_ksc.co.in
            expr: probe_http_status_code{instance="https://hsjk.co.in",job="blackbox"} != 200
            for: 1m
            labels:
              severity: critical
            annotations: 
              message: "HTTP status code for jlsj.co.in is not 200. The website is down."
          - alert: service_down_for_mails.in
            expr: probe_http_status_code{instance="https://mails.in",job="blackbox"} != 200
            for: 1m
            labels:
              severity: critical
            annotations: 
              message: "HTTP status code for mails.in is not 200. The website is down."
          - alert: service_down_for_klkskc.co.in
            expr: probe_http_status_code{instance="https://kajci.co.in",job="blackbox"} != 200
            for: 1m
            labels:
              severity: critical
            annotations: 
              message: "HTTP status code for ncsjn.co.in is not 200. The website is down."
          - alert: service_down_for_zkcn.co.in
            expr: probe_http_status_code{instance="https://lxhs.co.in",job="blackbox"} != 200
            for: 1m
            labels:
              severity: critical
            annotations: 
              message: "HTTP status code for csacv.co.in is not 200. The website is down."
      - name: Website SSL Monitoring
        rules:
          - alert: SSL_expiry_for_sacs.co.in
            expr: (probe_ssl_earliest_cert_expiry{instance="https://sacv.co.in"} - time()) / (60*60*24) <= 10
            for: 1m
            labels:
              severity: critical
            annotations: 
              message: "The SSL for scvvdi.co.in is going to expire in 10 days."
          - alert: SSL_expiry_for_scvsdav.sirpi.co.in
            expr: (probe_ssl_earliest_cert_expiry{instance="https://kcvdv.sirpi.co.in"} - time()) / (60*60*24) <= 10
            for: 1m
            labels:
              severity: critical
            annotations: 
              message: "The SSL for scvdsv.co.in is going to expire in 10 days."
          - alert: SSL_expiry_for_mail.in
            expr: (probe_ssl_earliest_cert_expiry{instance="https://mail.in"} - time()) / (60*60*24) <= 10
            for: 1m
            labels:
              severity: critical
            annotations: 
              message: "The SSL for mail.in is going to expire in 10 days."
          - alert: SSL_expiry_for_scvds.co.in
            expr: (probe_ssl_earliest_cert_expiry{instance="https://scdv.co.in"} - time()) / (60*60*24) <= 10
            for: 1m
            labels:
              severity: critical
            annotations: 
              message: "The SSL for scdsv.co.in is going to expire in 10 days."
          - alert: SSL_expiry_for_vsxcv.co.in
            expr: (probe_ssl_earliest_cert_expiry{instance="https://vscsd.co.in"} - time()) / (60*60*24) <= 10
            for: 1m
            labels:
              severity: critical
            annotations: 
              message: "The SSL for scvsv.co.in is going to expire in 10 days." 
           
           
  prometheus.yaml: |-
    global:
      scrape_interval: 15s
      scrape_timeout: 10s
      evaluation_interval: 1m
    alerting:
      alertmanagers:
      - kubernetes_sd_configs:
        - role: endpoints
          namespaces:
            names:
            - monitoring
        scheme: http
        path_prefix: /
        timeout: 10s
        relabel_configs:
        - source_labels: [__meta_kubernetes_namespace, __meta_kubernetes_service_label_k8s_app]
          separator: ;
          regex: monitoring;alertmanager
          replacement: $1
          action: keep
        - source_labels: [__meta_kubernetes_endpoint_port_name]
          separator: ;
          regex: http
          replacement: $1
          action: keep
    rule_files:
    - /etc/config/rules.yaml
    - /etc/config/alerts.yaml
    scrape_configs:
    - job_name: 'blackbox'
      scrape_interval: 15s
      metrics_path: /probe
      params:
        module: [http_2xx]
      static_configs:
        - targets:
          - https://scvdsv.co.in
          - https://windv.co.in
          - https://mail.in
          - https://win.co.in
          - https://vpn.in/
      relabel_configs:
        - source_labels: [__address__]
          target_label: __param_target
        - source_labels: [__param_target]
          target_label: instance
        - target_label: __address__
          replacement: prometheus-blackbox-exporter:9115
    - job_name: kubernetes-service-endpoints
      honor_timestamps: true
      scrape_interval: 15s
      scrape_timeout: 10s
      metrics_path: /metrics
      scheme: http
      kubernetes_sd_configs:
      - role: endpoints
      relabel_configs:
      - separator: ;
        regex: __meta_kubernetes_service_label_(.+)
        replacement: $1
        action: labelmap
      - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scrape]
        separator: ;
        regex: "true"
        replacement: $1
        action: keep
      - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_path]
        separator: ;
        regex: (.+)
        target_label: __metrics_path__
        replacement: $1
        action: replace
      - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scheme]
        separator: ;
        regex: (https?)
        target_label: __scheme__
        replacement: $1
        action: replace
      - source_labels: [__address__, __meta_kubernetes_service_annotation_prometheus_io_port]
        separator: ;
        regex: ([^:]+)(?::\d+)?;(\d+)
        target_label: __address__
        replacement: $1:$2
        action: replace
      - source_labels: [__meta_kubernetes_namespace]
        separator: ;
        regex: (.*)
        target_label: namespace
        replacement: $1
        action: replace
      - source_labels: [__meta_kubernetes_pod_name]
        separator: ;
        regex: (.*)
        target_label: pod
        replacement: $1
        action: replace
      - source_labels: [__meta_kubernetes_pod_name]
        separator: ;
        regex: (.*)
        target_label: instance
        replacement: $1
        action: replace
    - job_name: kubernetes-services
      honor_timestamps: true
      params:
        module:
        - http_2xx
      scrape_interval: 15s
      scrape_timeout: 10s
      metrics_path: /probe
      scheme: http
      kubernetes_sd_configs:
      - role: service
      relabel_configs:
      - separator: ;
        regex: __meta_kubernetes_service_label_(.+)
        replacement: $1
        action: labelmap
      - source_labels: [__address__]
        separator: ;
        regex: (.*)
        target_label: __param_target
        replacement: $1
        action: replace
      - separator: ;
        regex: (.*)
        target_label: __address__
        replacement: blackbox
        action: replace
      - source_labels: [__param_target]
        separator: ;
        regex: (.*)
        target_label: instance
        replacement: $1
        action: replace
      - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_probe]
        separator: ;
        regex: "true"
        replacement: $1
        action: keep
      - source_labels: [__meta_kubernetes_namespace]
        separator: ;
        regex: (.*)
        target_label: namespace
        replacement: $1
        action: replace
      - source_labels: [__meta_kubernetes_pod_name]
        separator: ;
        regex: (.*)
        target_label: pod
        replacement: $1
        action: replace
    - job_name: kubernetes-pods
      honor_timestamps: true
      scrape_interval: 15s
      scrape_timeout: 10s
      metrics_path: /metrics
      scheme: http
      kubernetes_sd_configs:
      - role: pod
      relabel_configs:
      - separator: ;
        regex: __meta_kubernetes_pod_label_(.+)
        replacement: $1
        action: labelmap
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
        separator: ;
        regex: "true"
        replacement: $1
        action: keep
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
        separator: ;
        regex: (.+)
        target_label: __metrics_path__
        replacement: $1
        action: replace
      - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
        separator: ;
        regex: ([^:]+)(?::\d+)?;(\d+)
        target_label: __address__
        replacement: $1:$2
        action: replace
      - source_labels: [__meta_kubernetes_namespace]
        separator: ;
        regex: (.*)
        target_label: namespace
        replacement: $1
        action: replace
      - source_labels: [__meta_kubernetes_pod_name]
        separator: ;
        regex: (.*)
        target_label: pod
        replacement: $1
        action: replace
      - source_labels: [__meta_kubernetes_pod_name]
        separator: ;
        regex: (.*)
        target_label: instance
        replacement: $1
        action: replace
    - job_name: alertmanager
      honor_timestamps: true
      scrape_interval: 15s
      scrape_timeout: 10s
      metrics_path: /metrics
      scheme: http
      kubernetes_sd_configs:
      - role: endpoints
      relabel_configs:
      - separator: ;
        regex: __meta_kubernetes_service_label_(.+)
        replacement: $1
        action: labelmap
      - source_labels: [__address__]
        separator: ;
        regex: ([^:]+)(?::\d+)?
        target_label: __address__
        replacement: $1:9093
        action: replace
      - source_labels: [__meta_kubernetes_namespace, __meta_kubernetes_service_label_k8s_app]
        separator: ;
        regex: monitoring;alertmanager
        replacement: $1
        action: keep
      - source_labels: [__meta_kubernetes_namespace]
        separator: ;
        regex: (.*)
        target_label: namespace
        replacement: $1
        action: replace
      - source_labels: [__meta_kubernetes_pod_name]
        separator: ;
        regex: (.*)
        target_label: pod
        replacement: $1
        action: replace
    - job_name: cadvisor
      honor_timestamps: true
      scrape_interval: 15s
      scrape_timeout: 10s
      metrics_path: /metrics
      scheme: https
      bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
      tls_config:
        ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        insecure_skip_verify: true
      kubernetes_sd_configs:
      - role: node
      relabel_configs:
      - separator: ;
        regex: __meta_kubernetes_node_label_(.+)
        replacement: $1
        action: labelmap
      - source_labels: [__address__]
        separator: ;
        regex: ([^:]+)(?::\d+)?
        target_label: __address__
        replacement: $1:10250
        action: replace
      - separator: ;
        regex: (.*)
        target_label: __metrics_path__
        replacement: /metrics/cadvisor
        action: replace
      metric_relabel_configs:
      - source_labels: [namespace]
        separator: ;
        regex: ^$
        replacement: $1
        action: drop
      - source_labels: [pod_name]
        separator: ;
        regex: ^$
        replacement: $1
        action: drop
    - job_name: apiserver
      honor_timestamps: true
      scrape_interval: 15s
      scrape_timeout: 10s
      metrics_path: /metrics
      kubernetes_sd_configs:
      - role: endpoints
      scheme: https
      bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
      tls_config:
        ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        insecure_skip_verify: true
      relabel_configs:
      - separator: ;
        regex: __meta_kubernetes_service_label_(.+)
        replacement: $1
        action: labelmap
      - source_labels: [__meta_kubernetes_namespace, __meta_kubernetes_service_name]
        separator: ;
        regex: default;kubernetes
        replacement: $1
        action: keep
      - source_labels: [__meta_kubernetes_endpoint_port_name]
        separator: ;
        regex: https
        replacement: $1
        action: keep
    - job_name: kube-state-metrics
      honor_timestamps: true
      scrape_interval: 15s
      scrape_timeout: 10s
      metrics_path: /metrics
      scheme: http
      kubernetes_sd_configs:
      - role: service
      relabel_configs:
      - separator: ;
        regex: __meta_kubernetes_service_label_(.+)
        replacement: $1
        action: labelmap
      - source_labels: [__meta_kubernetes_namespace, __meta_kubernetes_service_label_k8s_app]
        separator: ;
        regex: monitoring;kube-state-metrics
        replacement: $1
        action: keep
    - job_name: kubelet
      honor_timestamps: true
      scrape_interval: 15s
      scrape_timeout: 10s
      metrics_path: /metrics
      scheme: https
      bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
      tls_config:
        ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        insecure_skip_verify: true
      kubernetes_sd_configs:
      - role: node
      relabel_configs:
      - separator: ;
        regex: __meta_kubernetes_node_label_(.+)
        replacement: $1
        action: labelmap
      - source_labels: [__address__]
        separator: ;
        regex: ([^:]+)(?::\d+)?
        target_label: __address__
        replacement: $1:10250
        action: replace
    - job_name: node-exporter
      honor_timestamps: true
      scrape_interval: 15s
      scrape_timeout: 10s
      metrics_path: /metrics
      scheme: http
      kubernetes_sd_configs:
      - role: pod
      relabel_configs:
      - separator: ;
        regex: __meta_kubernetes_pod_label_(.+)
        replacement: $1
        action: labelmap
      - source_labels: [__address__]
        separator: ;
        regex: ([^:]+)(?::\d+)?
        target_label: __address__
        replacement: $1:9100
        action: replace
      - source_labels: [__meta_kubernetes_namespace, __meta_kubernetes_pod_label_k8s_app]
        separator: ;
        regex: monitoring;node-exporter
        replacement: $1
        action: keep
      - source_labels: [__meta_kubernetes_namespace]
        separator: ;
        regex: (.*)
        target_label: namespace
        replacement: $1
        action: replace
      - source_labels: [__meta_kubernetes_pod_name]
        separator: ;
        regex: (.*)
        target_label: pod
        replacement: $1
        action: replace
      - source_labels: [__meta_kubernetes_pod_node_name]
        separator: ;
        regex: (.*)
        target_label: instance
        replacement: $1
        action: replace
    - job_name: prometheus
      honor_timestamps: true
      scrape_interval: 15s
      scrape_timeout: 10s
      metrics_path: /metrics
      scheme: http
      kubernetes_sd_configs:
      - role: pod
      relabel_configs:
      - separator: ;
        regex: __meta_kubernetes_pod_label_(.+)
        replacement: $1
        action: labelmap
      - source_labels: [__address__]
        separator: ;
        regex: ([^:]+)(?::\d+)?
        target_label: __address__
        replacement: $1:9090
        action: replace
      - source_labels: [__meta_kubernetes_namespace, __meta_kubernetes_pod_label_k8s_app]
        separator: ;
        regex: monitoring;prometheus
        replacement: $1
        action: keep
      - source_labels: [__meta_kubernetes_namespace]
        separator: ;
        regex: (.*)
        target_label: namespace
        replacement: $1
        action: replace
      - source_labels: [__meta_kubernetes_pod_name]
        separator: ;
        regex: (.*)
        target_label: pod
        replacement: $1
        action: replace
      - source_labels: [__meta_kubernetes_pod_name]
        separator: ;
        regex: (.*)
        target_label: instance
        replacement: $1
        action: replace
  rules.yaml: "\"groups\": \n- \"name\": \"k8s.rules\"\n  \"rules\": \n
    \ - \"expr\": |\n      sum(rate(container_cpu_usage_seconds_total{job=\"cadvisor\",
    image!=\"\", container_name!=\"\"}[5m])) by (namespace)\n    \"record\": \"namespace:container_cpu_usage_seconds_total:sum_rate\"\n
    \ - \"expr\": |\n      sum by (namespace, pod_name, container_name) (\n        rate(container_cpu_usage_seconds_total{job=\"cadvisor\",
    image!=\"\", container_name!=\"\"}[5m])\n      )\n    \"record\": \"namespace_pod_name_container_name:container_cpu_usage_seconds_total:sum_rate\"\n
    \ - \"expr\": |\n      sum(container_memory_usage_bytes{job=\"cadvisor\", image!=\"\",
    container_name!=\"\"}) by (namespace)\n    \"record\": \"namespace:container_memory_usage_bytes:sum\"\n
    \ - \"expr\": |\n      sum by (namespace, label_name) (\n         sum(rate(container_cpu_usage_seconds_total{job=\"cadvisor\",
    image!=\"\", container_name!=\"\"}[5m])) by (namespace, pod_name)\n       * on
    (namespace, pod_name) group_left(label_name)\n         label_replace(kube_pod_labels{job=\"kube-state-metrics\"},
    \"pod_name\", \"$1\", \"pod\", \"(.*)\")\n      )\n    \"record\": \"namespace_name:container_cpu_usage_seconds_total:sum_rate\"\n
    \ - \"expr\": |\n      sum by (namespace, label_name) (\n        sum(container_memory_usage_bytes{job=\"cadvisor\",image!=\"\",
    container_name!=\"\"}) by (pod_name, namespace)\n      * on (namespace, pod_name)
    group_left(label_name)\n        label_replace(kube_pod_labels{job=\"kube-state-metrics\"},
    \"pod_name\", \"$1\", \"pod\", \"(.*)\")\n      )\n    \"record\": \"namespace_name:container_memory_usage_bytes:sum\"\n
    \ - \"expr\": |\n      sum by (namespace, label_name) (\n        sum(kube_pod_container_resource_requests_memory_bytes{job=\"kube-state-metrics\"}
    * on (endpoint, instance, job, namespace, pod, service) group_left(phase) (kube_pod_status_phase{phase=~\"^(Pending|Running)$\"}
    == 1)) by (namespace, pod)\n      * on (namespace, pod) group_left(label_name)\n
    \       label_replace(kube_pod_labels{job=\"kube-state-metrics\"}, \"pod_name\",
    \"$1\", \"pod\", \"(.*)\")\n      )\n    \"record\": \"namespace_name:kube_pod_container_resource_requests_memory_bytes:sum\"\n
    \ - \"expr\": |\n      sum by (namespace, label_name) (\n        sum(kube_pod_container_resource_requests_cpu_cores{job=\"kube-state-metrics\"}
    * on (endpoint, instance, job, namespace, pod, service) group_left(phase) (kube_pod_status_phase{phase=~\"^(Pending|Running)$\"}
    == 1)) by (namespace, pod)\n      * on (namespace, pod) group_left(label_name)\n
    \       label_replace(kube_pod_labels{job=\"kube-state-metrics\"}, \"pod_name\",
    \"$1\", \"pod\", \"(.*)\")\n      )\n    \"record\": \"namespace_name:kube_pod_container_resource_requests_cpu_cores:sum\"\n
    \ - \"expr\": |\n      sum(\n        label_replace(\n          label_replace(\n
    \           kube_pod_owner{job=\"kube-state-metrics\", owner_kind=\"ReplicaSet\"},\n
    \           \"replicaset\", \"$1\", \"owner_name\", \"(.*)\"\n          ) * on(replicaset,
    namespace) group_left(owner_name) kube_replicaset_owner{job=\"kube-state-metrics\"},\n
    \         \"workload\", \"$1\", \"owner_name\", \"(.*)\"\n        )\n      ) by
    (namespace, workload, pod)\n    \"labels\": \n      \"workload_type\": \"deployment\"\n
    \   \"record\": \"mixin_pod_workload\"\n  - \"expr\": |\n      sum(\n        label_replace(\n
    \         kube_pod_owner{job=\"kube-state-metrics\", owner_kind=\"DaemonSet\"},\n
    \         \"workload\", \"$1\", \"owner_name\", \"(.*)\"\n        )\n      ) by
    (namespace, workload, pod)\n    \"labels\": \n      \"workload_type\": \"daemonset\"\n
    \   \"record\": \"mixin_pod_workload\"\n  - \"expr\": |\n      sum(\n        label_replace(\n
    \         kube_pod_owner{job=\"kube-state-metrics\", owner_kind=\"StatefulSet\"},\n
    \         \"workload\", \"$1\", \"owner_name\", \"(.*)\"\n        )\n      ) by
    (namespace, workload, pod)\n    \"labels\": \n      \"workload_type\": \"statefulset\"\n
    \   \"record\": \"mixin_pod_workload\"\n- \"name\": \"kube-scheduler.rules\"\n
    \ \"rules\": \n  - \"expr\": |\n      histogram_quantile(0.99, sum(rate(scheduler_e2e_scheduling_latency_microseconds_bucket{job=\"kube-scheduler\"}[5m]))
    without(instance, pod)) / 1e+06\n    \"labels\": \n      \"quantile\": \"0.99\"\n
    \   \"record\": \"cluster_quantile:scheduler_e2e_scheduling_latency:histogram_quantile\"\n
    \ - \"expr\": |\n      histogram_quantile(0.99, sum(rate(scheduler_scheduling_algorithm_latency_microseconds_bucket{job=\"kube-scheduler\"}[5m]))
    without(instance, pod)) / 1e+06\n    \"labels\": \n      \"quantile\": \"0.99\"\n
    \   \"record\": \"cluster_quantile:scheduler_scheduling_algorithm_latency:histogram_quantile\"\n
    \ - \"expr\": |\n      histogram_quantile(0.99, sum(rate(scheduler_binding_latency_microseconds_bucket{job=\"kube-scheduler\"}[5m]))
    without(instance, pod)) / 1e+06\n    \"labels\": \n      \"quantile\": \"0.99\"\n
    \   \"record\": \"cluster_quantile:scheduler_binding_latency:histogram_quantile\"\n
    \ - \"expr\": |\n      histogram_quantile(0.9, sum(rate(scheduler_e2e_scheduling_latency_microseconds_bucket{job=\"kube-scheduler\"}[5m]))
    without(instance, pod)) / 1e+06\n    \"labels\": \n      \"quantile\": \"0.9\"\n
    \   \"record\": \"cluster_quantile:scheduler_e2e_scheduling_latency:histogram_quantile\"\n
    \ - \"expr\": |\n      histogram_quantile(0.9, sum(rate(scheduler_scheduling_algorithm_latency_microseconds_bucket{job=\"kube-scheduler\"}[5m]))
    without(instance, pod)) / 1e+06\n    \"labels\": \n      \"quantile\": \"0.9\"\n
    \   \"record\": \"cluster_quantile:scheduler_scheduling_algorithm_latency:histogram_quantile\"\n
    \ - \"expr\": |\n      histogram_quantile(0.9, sum(rate(scheduler_binding_latency_microseconds_bucket{job=\"kube-scheduler\"}[5m]))
    without(instance, pod)) / 1e+06\n    \"labels\": \n      \"quantile\": \"0.9\"\n
    \   \"record\": \"cluster_quantile:scheduler_binding_latency:histogram_quantile\"\n
    \ - \"expr\": |\n      histogram_quantile(0.5, sum(rate(scheduler_e2e_scheduling_latency_microseconds_bucket{job=\"kube-scheduler\"}[5m]))
    without(instance, pod)) / 1e+06\n    \"labels\": \n      \"quantile\": \"0.5\"\n
    \   \"record\": \"cluster_quantile:scheduler_e2e_scheduling_latency:histogram_quantile\"\n
    \ - \"expr\": |\n      histogram_quantile(0.5, sum(rate(scheduler_scheduling_algorithm_latency_microseconds_bucket{job=\"kube-scheduler\"}[5m]))
    without(instance, pod)) / 1e+06\n    \"labels\": \n      \"quantile\": \"0.5\"\n
    \   \"record\": \"cluster_quantile:scheduler_scheduling_algorithm_latency:histogram_quantile\"\n
    \ - \"expr\": |\n      histogram_quantile(0.5, sum(rate(scheduler_binding_latency_microseconds_bucket{job=\"kube-scheduler\"}[5m]))
    without(instance, pod)) / 1e+06\n    \"labels\": \n      \"quantile\": \"0.5\"\n
    \   \"record\": \"cluster_quantile:scheduler_binding_latency:histogram_quantile\"\n-
    \"name\": \"kube-apiserver.rules\"\n  \"rules\": \n  - \"expr\": |\n      histogram_quantile(0.99,
    sum(rate(apiserver_request_latencies_bucket{job=\"apiserver\"}[5m])) without(instance,
    pod)) / 1e+06\n    \"labels\": \n      \"quantile\": \"0.99\"\n    \"record\":
    \"cluster_quantile:apiserver_request_latencies:histogram_quantile\"\n  - \"expr\":
    |\n      histogram_quantile(0.9, sum(rate(apiserver_request_latencies_bucket{job=\"apiserver\"}[5m]))
    without(instance, pod)) / 1e+06\n    \"labels\": \n      \"quantile\": \"0.9\"\n
    \   \"record\": \"cluster_quantile:apiserver_request_latencies:histogram_quantile\"\n
    \ - \"expr\": |\n      histogram_quantile(0.5, sum(rate(apiserver_request_latencies_bucket{job=\"apiserver\"}[5m]))
    without(instance, pod)) / 1e+06\n    \"labels\": \n      \"quantile\": \"0.5\"\n
    \   \"record\": \"cluster_quantile:apiserver_request_latencies:histogram_quantile\"\n-
    \"name\": \"node.rules\"\n  \"rules\": \n  - \"expr\": \"sum(min(kube_pod_info)
    by (node))\"\n    \"record\": \":kube_pod_info_node_count:\"\n  - \"expr\": |\n
    \     max(label_replace(kube_pod_info{job=\"kube-state-metrics\"}, \"pod\", \"$1\",
    \"pod\", \"(.*)\")) by (node, namespace, pod)\n    \"record\": \"node_namespace_pod:kube_pod_info:\"\n
    \ - \"expr\": |\n      count by (node) (sum by (node, cpu) (\n        node_cpu_seconds_total{job=\"node-exporter\"}\n
    \     * on (namespace, pod) group_left(node)\n        node_namespace_pod:kube_pod_info:\n
    \     ))\n    \"record\": \"node:node_num_cpu:sum\"\n  - \"expr\": |\n      1
    - avg(rate(node_cpu_seconds_total{job=\"node-exporter\",mode=\"idle\"}[1m]))\n
    \   \"record\": \":node_cpu_utilisation:avg1m\"\n  - \"expr\": |\n      1 - avg
    by (node) (\n        rate(node_cpu_seconds_total{job=\"node-exporter\",mode=\"idle\"}[1m])\n
    \     * on (namespace, pod) group_left(node)\n        node_namespace_pod:kube_pod_info:)\n
    \   \"record\": \"node:node_cpu_utilisation:avg1m\"\n  - \"expr\": |\n      node:node_cpu_utilisation:avg1m\n
    \       *\n      node:node_num_cpu:sum\n        /\n      scalar(sum(node:node_num_cpu:sum))\n
    \   \"record\": \"node:cluster_cpu_utilisation:ratio\"\n  - \"expr\": |\n      sum(node_load1{job=\"node-exporter\"})\n
    \     /\n      sum(node:node_num_cpu:sum)\n    \"record\": \":node_cpu_saturation_load1:\"\n
    \ - \"expr\": |\n      sum by (node) (\n        node_load1{job=\"node-exporter\"}\n
    \     * on (namespace, pod) group_left(node)\n        node_namespace_pod:kube_pod_info:\n
    \     )\n      /\n      node:node_num_cpu:sum\n    \"record\": \"node:node_cpu_saturation_load1:\"\n
    \ - \"expr\": |\n      1 -\n      sum(node_memory_MemFree_bytes{job=\"node-exporter\"}
    + node_memory_Cached_bytes{job=\"node-exporter\"} + node_memory_Buffers_bytes{job=\"node-exporter\"})\n
    \     /\n      sum(node_memory_MemTotal_bytes{job=\"node-exporter\"})\n    \"record\":
    \":node_memory_utilisation:\"\n  - \"expr\": |\n      sum(node_memory_MemFree_bytes{job=\"node-exporter\"}
    + node_memory_Cached_bytes{job=\"node-exporter\"} + node_memory_Buffers_bytes{job=\"node-exporter\"})\n
    \   \"record\": \":node_memory_MemFreeCachedBuffers_bytes:sum\"\n  - \"expr\":
    |\n      sum(node_memory_MemTotal_bytes{job=\"node-exporter\"})\n    \"record\":
    \":node_memory_MemTotal_bytes:sum\"\n  - \"expr\": |\n      sum by (node) (\n
    \       (node_memory_MemFree_bytes{job=\"node-exporter\"} + node_memory_Cached_bytes{job=\"node-exporter\"}
    + node_memory_Buffers_bytes{job=\"node-exporter\"})\n        * on (namespace,
    pod) group_left(node)\n          node_namespace_pod:kube_pod_info:\n      )\n
    \   \"record\": \"node:node_memory_bytes_available:sum\"\n  - \"expr\": |\n      sum
    by (node) (\n        node_memory_MemTotal_bytes{job=\"node-exporter\"}\n        *
    on (namespace, pod) group_left(node)\n          node_namespace_pod:kube_pod_info:\n
    \     )\n    \"record\": \"node:node_memory_bytes_total:sum\"\n  - \"expr\": |\n
    \     (node:node_memory_bytes_total:sum - node:node_memory_bytes_available:sum)\n
    \     /\n      node:node_memory_bytes_total:sum\n    \"record\": \"node:node_memory_utilisation:ratio\"\n
    \ - \"expr\": |\n      (node:node_memory_bytes_total:sum - node:node_memory_bytes_available:sum)\n
    \     /\n      scalar(sum(node:node_memory_bytes_total:sum))\n    \"record\":
    \"node:cluster_memory_utilisation:ratio\"\n  - \"expr\": |\n      1e3 * sum(\n
    \       (rate(node_vmstat_pgpgin{job=\"node-exporter\"}[1m])\n       + rate(node_vmstat_pgpgout{job=\"node-exporter\"}[1m]))\n
    \     )\n    \"record\": \":node_memory_swap_io_bytes:sum_rate\"\n  - \"expr\":
    |\n      1 -\n      sum by (node) (\n        (node_memory_MemFree_bytes{job=\"node-exporter\"}
    + node_memory_Cached_bytes{job=\"node-exporter\"} + node_memory_Buffers_bytes{job=\"node-exporter\"})\n
    \     * on (namespace, pod) group_left(node)\n        node_namespace_pod:kube_pod_info:\n
    \     )\n      /\n      sum by (node) (\n        node_memory_MemTotal_bytes{job=\"node-exporter\"}\n
    \     * on (namespace, pod) group_left(node)\n        node_namespace_pod:kube_pod_info:\n
    \     )\n    \"record\": \"node:node_memory_utilisation:\"\n  - \"expr\": |\n
    \     1 - (node:node_memory_bytes_available:sum / node:node_memory_bytes_total:sum)\n
    \   \"record\": \"node:node_memory_utilisation_2:\"\n  - \"expr\": |\n      1e3
    * sum by (node) (\n        (rate(node_vmstat_pgpgin{job=\"node-exporter\"}[1m])\n
    \      + rate(node_vmstat_pgpgout{job=\"node-exporter\"}[1m]))\n       * on (namespace,
    pod) group_left(node)\n         node_namespace_pod:kube_pod_info:\n      )\n    \"record\":
    \"node:node_memory_swap_io_bytes:sum_rate\"\n  - \"expr\": |\n      avg(irate(node_disk_io_time_seconds_total{job=\"node-exporter\",device=~\"nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+\"}[1m]))\n
    \   \"record\": \":node_disk_utilisation:avg_irate\"\n  - \"expr\": |\n      avg
    by (node) (\n        irate(node_disk_io_time_seconds_total{job=\"node-exporter\",device=~\"nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+\"}[1m])\n
    \     * on (namespace, pod) group_left(node)\n        node_namespace_pod:kube_pod_info:\n
    \     )\n    \"record\": \"node:node_disk_utilisation:avg_irate\"\n  - \"expr\":
    |\n      avg(irate(node_disk_io_time_weighted_seconds_total{job=\"node-exporter\",device=~\"nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+\"}[1m]))\n
    \   \"record\": \":node_disk_saturation:avg_irate\"\n  - \"expr\": |\n      avg
    by (node) (\n        irate(node_disk_io_time_weighted_seconds_total{job=\"node-exporter\",device=~\"nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+\"}[1m])\n
    \     * on (namespace, pod) group_left(node)\n        node_namespace_pod:kube_pod_info:\n
    \     )\n    \"record\": \"node:node_disk_saturation:avg_irate\"\n  - \"expr\":
    |\n      max by (instance, namespace, pod, device) ((node_filesystem_size_bytes{fstype=~\"ext[234]|btrfs|xfs|zfs\"}\n
    \     - node_filesystem_avail_bytes{fstype=~\"ext[234]|btrfs|xfs|zfs\"})\n      /
    node_filesystem_size_bytes{fstype=~\"ext[234]|btrfs|xfs|zfs\"})\n    \"record\":
    \"node:node_filesystem_usage:\"\n  - \"expr\": |\n      max by (instance, namespace,
    pod, device) (node_filesystem_avail_bytes{fstype=~\"ext[234]|btrfs|xfs|zfs\"}
    / node_filesystem_size_bytes{fstype=~\"ext[234]|btrfs|xfs|zfs\"})\n    \"record\":
    \"node:node_filesystem_avail:\"\n  - \"expr\": |\n      sum(irate(node_network_receive_bytes_total{job=\"node-exporter\",device!~\"veth.+\"}[1m]))
    +\n      sum(irate(node_network_transmit_bytes_total{job=\"node-exporter\",device!~\"veth.+\"}[1m]))\n
    \   \"record\": \":node_net_utilisation:sum_irate\"\n  - \"expr\": |\n      sum
    by (node) (\n        (irate(node_network_receive_bytes_total{job=\"node-exporter\",device!~\"veth.+\"}[1m])
    +\n        irate(node_network_transmit_bytes_total{job=\"node-exporter\",device!~\"veth.+\"}[1m]))\n
    \     * on (namespace, pod) group_left(node)\n        node_namespace_pod:kube_pod_info:\n
    \     )\n    \"record\": \"node:node_net_utilisation:sum_irate\"\n  - \"expr\":
    |\n      sum(irate(node_network_receive_drop_total{job=\"node-exporter\",device!~\"veth.+\"}[1m]))
    +\n      sum(irate(node_network_transmit_drop_total{job=\"node-exporter\",device!~\"veth.+\"}[1m]))\n
    \   \"record\": \":node_net_saturation:sum_irate\"\n  - \"expr\": |\n      sum
    by (node) (\n        (irate(node_network_receive_drop_total{job=\"node-exporter\",device!~\"veth.+\"}[1m])
    +\n        irate(node_network_transmit_drop_total{job=\"node-exporter\",device!~\"veth.+\"}[1m]))\n
    \     * on (namespace, pod) group_left(node)\n        node_namespace_pod:kube_pod_info:\n
    \     )\n    \"record\": \"node:node_net_saturation:sum_irate\"\n  - \"expr\":
    |\n      max(\n        max(\n          kube_pod_info{job=\"kube-state-metrics\",
    host_ip!=\"\"}\n        ) by (node, host_ip)\n        * on (host_ip) group_right
    (node)\n        label_replace(\n          (max(node_filesystem_files{job=\"node-exporter\",
    mountpoint=\"/\"}) by (instance)), \"host_ip\", \"$1\", \"instance\", \"(.*):.*\"\n
    \       )\n      ) by (node)\n    \"record\": \"node:node_inodes_total:\"\n  -
    \"expr\": |\n      max(\n        max(\n          kube_pod_info{job=\"kube-state-metrics\",
    host_ip!=\"\"}\n        ) by (node, host_ip)\n        * on (host_ip) group_right
    (node)\n        label_replace(\n          (max(node_filesystem_files_free{job=\"node-exporter\",
    mountpoint=\"/\"}) by (instance)), \"host_ip\", \"$1\", \"instance\", \"(.*):.*\"\n
    \       )\n      ) by (node)\n    \"record\": \"node:node_inodes_free:\"\n"
---
kind: Service
apiVersion: v1
metadata:
  name: monitoring-prometheus
  labels:
    k8s-app: prometheus
    app.kubernetes.io/name: monitoring
    app.kubernetes.io/component: prometheus
spec:
  ports:
    # Exposes `http` and `TCP` ports `9090` using the default `ClusterIP` Service type
    - name: http
      port: 9090
      protocol: TCP
      targetPort: 9090
  # Ensures clients are routed to the same Prometheus Pod, which is necessary to get consistent dashboards in a highly-available setup. 
  # To learn more about Prometheus high availability, 
  # consult https://github.com/coreos/prometheus-operator/blob/master/Documentation/high-availability.md#prometheus
  sessionAffinity: ClientIP
  selector:
    k8s-app: prometheus
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: monitoring-prometheus
  labels: &Labels
    k8s-app: prometheus
    app.kubernetes.io/name: monitoring
    app.kubernetes.io/component: prometheus
spec:
  serviceName: "monitoring-prometheus"
  replicas: 1
  podManagementPolicy: "Parallel"
  updateStrategy:
    type: "RollingUpdate"
  selector:
    matchLabels: *Labels
  template:
    metadata:
      labels: *Labels
    spec:
      serviceAccountName: prometheus
      # `chown` the Prometheus  `/data` directory so that Prometheus can write to it
      initContainers:
      - name: "init-chown-data"
        image: debian:9
        imagePullPolicy: Always
        command: ["chown", "-R", "65534:65534", "/data"]
        volumeMounts:
        - name: monitoring-prometheus-data
          mountPath: /data
          subPath: ""
      containers:
        - name: prometheus-server
          # Use the `quay.io/prometheus/prometheus:v2.11.1` image
          image: quay.io/prometheus/prometheus:v2.11.1
          imagePullPolicy: "IfNotPresent"
          args:
            - --config.file=/etc/config/prometheus.yaml
            - --storage.tsdb.path=/data
            - --web.console.libraries=/etc/prometheus/console_libraries
            - --web.console.templates=/etc/prometheus/consoles
            - --web.enable-lifecycle
          ports:
            - containerPort: 9090
          # Probe the `/-/ready` and `/-/healthy` endpoints
          readinessProbe:
            httpGet:
              path: /-/ready
              port: 9090
            initialDelaySeconds: 30
            timeoutSeconds: 30
          livenessProbe:
            httpGet:
              path: /-/healthy
              port: 9090
            initialDelaySeconds: 30
            timeoutSeconds: 30
          # Based on 10 running nodes with 30 pods each
          # Resource requests of `200m` of CPU and `1000Mi` of memory
          resources:
            requests:
              cpu: 200m
              memory: 1000Mi
          volumeMounts:
            - name: config-volume
              mountPath: /etc/config
            - name: monitoring-prometheus-data
              mountPath: /data
              subPath: ""
      terminationGracePeriodSeconds: 300
      volumes:
        # The Prometheus ConfigMap is mounted into the Pods as a volume at `/etc/config`
        - name: config-volume
          configMap:
            name: monitoring-prometheus-config
      # Configures Pod anti-affinity so that Prometheus Pods are assigned to different Nodes. 
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: k8s-app
                operator: In
                values:
                - prometheus
            topologyKey: "kubernetes.io/hostname"
  # A `volumeClaimTemplate` of `16Gi` of Block Storage is configured and used for Prometheus data storage, mounted at `/data/`
  volumeClaimTemplates:
  - metadata:
      name: monitoring-prometheus-data
      labels: *Labels
    spec:
      storageClassName: hcloud-volumes
      accessModes:
        - ReadWriteOnce
      resources:
        requests:
          storage: "16Gi"